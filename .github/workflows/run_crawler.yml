# name: Run Daily Crawler

# on:
#   schedule:
#     - cron: '0 9 * * *'   # UTC 09:00 = KST 18:00 매일 실행
#   workflow_dispatch:

# jobs:
#   run-crawler:
#     runs-on: ubuntu-latest

#     steps:
#     - name: Checkout repository
#       uses: actions/checkout@v4

#     - name: Set up Python
#       uses: actions/setup-python@v5
#       with:
#         python-version: '3.10'

#     - name: Install dependencies
#       run: |
#         python -m pip install --upgrade pip
#         pip install -r requirements.txt

#     - name: Run crawler
#       run: |
#         python src/crawler.py

name: Run Daily Crawler with H2

on:
  schedule:
    - cron: '0 9 * * *'
  workflow_dispatch:

jobs:
  run-crawler:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Run crawler with H2
        run: |
          export DATABASE_URL="jdbc:h2:mem:kospi?MODE=MYSQL;DB_CLOSE_DELAY=-1"
          python src/crawler.py
